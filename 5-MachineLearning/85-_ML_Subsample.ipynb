{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creation Date:\n",
    "##### February 19 2022\n",
    "##### Created By Alperen KOLAMUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from IPython.display import display\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(\"tmp/bulldozers_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(df, col, name):\n",
    "    if not is_numeric_dtype(col):\n",
    "        df[name] = col.cat.codes + 1 # ortak ağız için"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing(df, col, name, nan_dict, is_train):\n",
    "    if is_train:\n",
    "        if is_numeric_dtype(col):\n",
    "            if pd.isnull(col).sum():\n",
    "                df[name+\"_NA\"] = pd.isnull(col)\n",
    "                nan_dict[name] = col.median()\n",
    "                df[name] = col.fillna(nan_dict[name])\n",
    "\n",
    "    else:\n",
    "        if is_numeric_dtype(col):\n",
    "            if name in nan_dict:\n",
    "                df[name+\"_NA\"] = pd.isnull(col)\n",
    "                df[name] = col.fillna(nan_dict[name])\n",
    "            \n",
    "            else:\n",
    "                df[name] = col.fillna(df[name].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_df(df, y_fld, nan_dict=None, is_train=True):\n",
    "    df = df.copy()\n",
    "    y = df[y_fld].values\n",
    "\n",
    "    df.drop([y_fld], axis=1, inplace=True)\n",
    "\n",
    "    if nan_dict is None:\n",
    "        nan_dict = {}\n",
    "    \n",
    "    for n, c in df.items():\n",
    "        fix_missing(df, c, n, nan_dict, is_train)\n",
    "        numericalize(df, c, n)\n",
    "\n",
    "    if is_train:\n",
    "        return df, y, nan_dict\n",
    "    \n",
    "    return df, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(df, n):\n",
    "    return(df[:n].copy(), df[n:].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_valid = 12000\n",
    "n_train = len(df)-n_valid\n",
    "raw_train, raw_valid = split_train_val(df, n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_raw, y_train_raw, nas = proc_df(raw_train, 'SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, nas = proc_df(raw_train, 'SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, y_valid = proc_df(raw_valid, 'SalePrice', nan_dict=nas, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x, y):\n",
    "    return math.sqrt(((x-y)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(m):\n",
    "\n",
    "    print(f\"RMSLE of train set {rmse(m.predict(x_train), y_train)}\")\n",
    "    print(f\"RMSLE of validation set {rmse(m.predict(x_valid), y_valid)}\")\n",
    "    print(f\"R^2 of train set {m.score(x_train, y_train)}\")\n",
    "    print(f\"R^2 of validation set {m.score(x_valid, y_valid)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Farklı Şeyleri Hızlı Şekilde Denemek\n",
    "* Elimizdeki probleme uygun modeli bulmak için çok şey denememiz gerekebilir\n",
    "* Bu iteratif süreci hızlı bir hale getirmek için model seçme kısmını subsample alarak yapabiliriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset Yaratma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(df, n):\n",
    "    idxs = np.random.permutation(len(df))[:n]\n",
    "    return idxs, df.iloc[idxs].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bütün verini model seçmek için kullanman gerekmez\n",
    "* En son eğitmek için gerekir\n",
    "* Validation seti değiştirmek istemiyorum, sadece train içinde subset alacağım\n",
    "\n",
    "\n",
    "|        | **Train** | **Validation** |\n",
    "|--------|:---------:|:--------------:|\n",
    "|        |  **300K** |     **1M**     |\n",
    "| **M1** |    0.64   |      0.75      |\n",
    "| **M2** |    0.67   |      0.79      |\n",
    "| **M3** |    0.58   |      0.68      |\n",
    "| **M4** |    0.44   |      0.57      |\n",
    "\n",
    "* Örnekte görüldüğü gibi M2 300K'lık veride `Train`'de en yüksek skoru yapmış. Yine aynı şekilde 1M'luk veride `Validation`'da da yüksek skor yapmış diğer modellere göre. O zaman `Train`'de en yüksek yapan `Validation`'da da yüksek sonuç verecektir. Sırf bunu test etmek için 1M veriyi diğer modellerde de test ederek zaman kaybetmeye gerek yok. `Train`'de en yüksek 2 tane M2 ve M1'i `Validation`'da test etmek daha doğru olacaktır\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs, x_train = get_sample(x_train, 3000)\n",
    "y_train = y_train[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 594 ms\n",
      "Wall time: 98.4 ms\n",
      "RMSLE of train set 0.14145120231004832\n",
      "RMSLE of validation set 0.35261117677243714\n",
      "R^2 of train set 0.9573240635941189\n",
      "R^2 of validation set 0.7500761460648667\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=10, n_jobs=-1)\n",
    "%time m.fit(x_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.81 s\n",
      "Wall time: 235 ms\n",
      "RMSLE of train set 0.12153577784010855\n",
      "RMSLE of validation set 0.34049898048255495\n",
      "R^2 of train set 0.9684951031135548\n",
      "R^2 of validation set 0.7669510272928001\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=30, n_jobs=-1)\n",
    "%time m.fit(x_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tüm Veri İle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, nas = proc_df(raw_train, 'SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, y_valid = proc_df(raw_valid, 'SalePrice', nan_dict=nas, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 39s\n",
      "Wall time: 10.4 s\n",
      "RMSLE of train set 0.09035467988577847\n",
      "RMSLE of validation set 0.2555905513575876\n",
      "R^2 of train set 0.9827703577282123\n",
      "R^2 of validation set 0.8686877778630461\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=10, n_jobs=-1)\n",
    "%time m.fit(x_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6min 29s\n",
      "Wall time: 29.3 s\n",
      "RMSLE of train set 0.07929675199313088\n",
      "RMSLE of validation set 0.2494024121846643\n",
      "R^2 of train set 0.9867295467857662\n",
      "R^2 of validation set 0.8749692430971017\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=30, n_jobs=-1)\n",
    "%time m.fit(x_train, y_train)\n",
    "print_score(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6d93cea15aa25cd6154ad73ef5572c382c028374c9d3d90f02e468d8b485a80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
